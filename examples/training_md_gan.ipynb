{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "# Imports for this repository\n",
    "from simplex_generator import simplex_params\n",
    "from losses import gaussian_likelihood_sum\n",
    "from architectures import LambdaNetwork, Discriminator, Generator\n",
    "from gmm_data_generator import load_db\n",
    "from numpy_dataset import NumpyDataset\n",
    "from md_gan_training import MDGANTraining"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "PARAMS = {'batch_size': 500,\n",
    "          'zdim': 2,\n",
    "          'gamma':0.5,\n",
    "          'beta1':0.5,\n",
    "          'beta2':0.999,\n",
    "          'n_lr_steps':3,\n",
    "          'lambda_training_iterations':10001,\n",
    "          'epochs':2000,\n",
    "          'eta_lambda': 0.01,\n",
    "          'e_dim': 9,\n",
    "          'lr_d': 1e-3,\n",
    "          'lr_g': 1e-3,\n",
    "          'epsilon': 1e-8,  # for avoiding numerical instabilities\n",
    "          'samp_num_gen': 2500}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Init Simplex and Working Device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Current Working Device is set to:cuda\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "working_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Find working device\n",
    "simplex = simplex_params(PARAMS['e_dim'], working_device) # Create Simplex\n",
    "print(\"Current Working Device is set to:\" + str(working_device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Search for $\\lambda$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "100%|██████████| 10001/10001 [00:13<00:00, 767.94it/s]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Lambda Loss:3.812762498855591\n",
      "Lambda Loss:3.812762498855591\n",
      "Lambda Loss:3.812762498855591\n",
      "Lambda Loss:3.812762498855591\n",
      "Lambda Loss:3.812762498855591\n",
      "Lambda Loss:3.812762498855591\n",
      "Lambda Loss:3.812762498855591\n",
      "Lambda Loss:3.812762498855591\n",
      "Lambda Loss:3.812762498855591\n",
      "Lambda Loss:3.812762498855591\n",
      "0.02208706922829151\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "lambda_net = LambdaNetwork(PARAMS['e_dim']).to(working_device)\n",
    "lambda_training_data = torch.tensor([1.0], device=working_device, dtype=torch.float32, requires_grad=False)\n",
    "optimizer_lambda = optim.Adam(lambda_net.parameters(), lr=PARAMS['eta_lambda'])\n",
    "\n",
    "for i in tqdm(range(PARAMS['lambda_training_iterations'])):\n",
    "    optimizer_lambda.zero_grad()\n",
    "    e = lambda_net(lambda_training_data)\n",
    "    lambda_lk = gaussian_likelihood_sum(e, simplex)\n",
    "    lambda_loss = -torch.log(PARAMS['epsilon'] + lambda_lk).mean()\n",
    "    if i % 1000 == 0 and i > 0:\n",
    "        print(\"Lambda Loss:\" + str(lambda_loss.item()))\n",
    "        for group in optimizer_lambda.param_groups:\n",
    "            group['lr'] = group['lr'] * PARAMS['gamma']\n",
    "    lambda_loss.backward()\n",
    "    optimizer_lambda.step()\n",
    "e = lambda_net(lambda_training_data)\n",
    "lambda_value = gaussian_likelihood_sum(e, simplex).sum().item()\n",
    "print(lambda_value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Generator and Discriminator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      " 13%|█▎        | 258/2000 [00:42<04:37,  6.28it/s]"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Learning rate steps: [500, 1000, 1500]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "net_g = Generator(PARAMS['zdim']).to(working_device) # Init generator function\n",
    "net_d = Discriminator(PARAMS['e_dim']).to(working_device) # Init discriminator function\n",
    "optimizer_g = optim.Adam(net_g.parameters(), lr=PARAMS['lr_g'], betas=(PARAMS['beta1'], PARAMS['beta2']))\n",
    "optimizer_d = optim.Adam(net_d.parameters(), lr=PARAMS['lr_d'], betas=(PARAMS['beta1'], PARAMS['beta2']))\n",
    "\n",
    "epoch_step_size=PARAMS['epochs']/(PARAMS['n_lr_steps']+1) # calculate learning rate decay step size\n",
    "lr_steps=[int((i+1)*epoch_step_size) for i in range(PARAMS['n_lr_steps'])] \n",
    "print(\"Learning rate steps:\",lr_steps)\n",
    "lr_g = optim.lr_scheduler.MultiStepLR(optimizer_g, lr_steps, gamma=PARAMS['gamma'])\n",
    "lr_d = optim.lr_scheduler.MultiStepLR(optimizer_d, lr_steps, gamma=PARAMS['gamma'])\n",
    "\n",
    "training_data = load_db()\n",
    "train_dataset = NumpyDataset(training_data)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=PARAMS['batch_size'],\n",
    "                                           shuffle=True)\n",
    "\n",
    "md_gan_training=MDGANTraining(net_d, net_g, optimizer_d,optimizer_g,PARAMS['batch_size'], PARAMS['zdim'], simplex,\n",
    "                     PARAMS['epsilon'],\n",
    "                     lambda_value,\n",
    "                     working_device)\n",
    "# Start Training Loop\n",
    "for epoch in tqdm(range(PARAMS['epochs'])):\n",
    "    for d in train_loader:\n",
    "        d = d.to(working_device)\n",
    "        md_gan_training.update_discriminator(d)\n",
    "        md_gan_training.update_generator()\n",
    "\n",
    "    lr_g.step(epoch) # update Generator learning rate\n",
    "    lr_d.step(epoch) # update Discriminator learning rate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot Samples for Generator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "g_samples = net_g(torch.randn(PARAMS['batch_size'], PARAMS['zdim']).to(working_device))\n",
    "g_samples = g_samples.cpu().detach().numpy()\n",
    "\n",
    "plt.plot(training_data[:, 0], training_data[:, 1], 'o',label='real data')\n",
    "plt.plot(g_samples[:, 0], g_samples[:, 1], '^',label='MD-GAN')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(r'$x_o$')\n",
    "plt.ylabel(r'$x_1$')\n",
    "plt.show() "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}